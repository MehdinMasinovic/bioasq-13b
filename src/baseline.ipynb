{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1fbb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import requests\n",
    "import json\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929bceaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/saito/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/saito/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /Users/saito/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ssl\n",
    "\n",
    "# Diable SSL verification to avoid certificate errors when downloaing nltk resources\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "# Download nltk stopwords and punkt tokenizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af1cf5e",
   "metadata": {},
   "source": [
    "## Loading training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d1db5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of BioASQ 13b questions: 10\n"
     ]
    }
   ],
   "source": [
    "from utils import load_bioasq_questions\n",
    "bioasq_13b_questions = load_bioasq_questions('../data/BioASQ-training13b/training13b.json', num_questions=10)\n",
    "\n",
    "# Check the number of questions\n",
    "print(f\"Number of BioASQ 13b questions: {len(bioasq_13b_questions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7cdd0f",
   "metadata": {},
   "source": [
    "## PubMed's API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea062f0f",
   "metadata": {},
   "source": [
    "## Traditional IR model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaaa825",
   "metadata": {},
   "source": [
    "### Step 1: Extract keywords from questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea21062",
   "metadata": {},
   "source": [
    "#### Remove stop words and punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c9529fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original question body:\n",
      "Is Hirschsprung disease a mendelian or a multifactorial disorder?\n",
      "\n",
      "Extracted keywords:\n",
      "['hirschsprung', 'disease', 'mendelian', 'multifactorial', 'disorder']\n"
     ]
    }
   ],
   "source": [
    "from utils import extract_keywords\n",
    "\n",
    "# For each question, extract keywords and save them in a attribute keywords\n",
    "for question in bioasq_13b_questions:\n",
    "    question['keywords'] = extract_keywords(question['body'])\n",
    "\n",
    "print(\"Original question body:\")\n",
    "print(bioasq_13b_questions[0]['body'])\n",
    "print(\"\\nExtracted keywords:\")\n",
    "print(bioasq_13b_questions[0]['keywords'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343bd797",
   "metadata": {},
   "source": [
    "### Step 2: Consume PubMed's API to get relevant documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c57ebe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents found for question `55031181e9bde69634000014`: 3\n",
      "Documents found for question `55046d5ff8aee20f27000007`: 0\n",
      "Documents found for question `54e25eaaae9738404b000017`: 4\n",
      "Documents found for question `535d292a9a4572de6f000003`: 25\n",
      "Documents found for question `55262a9787ecba3764000009`: 25\n",
      "Documents found for question `51406e6223fec90375000009`: 0\n",
      "Documents found for question `553fa78b1d53b76422000007`: 11\n",
      "Documents found for question `5149199dd24251bc05000040`: 25\n",
      "Documents found for question `52bf1db603868f1b06000011`: 4\n",
      "Documents found for question `5709e4b2cf1c32585100001c`: 0\n"
     ]
    }
   ],
   "source": [
    "# Get the most relevant documents for each question according to the PubMed API\n",
    "# and save them in a new attribute documents_api\n",
    "from utils import get_most_relevant_documents\n",
    "\n",
    "for question in bioasq_13b_questions:\n",
    "    documents = get_most_relevant_documents(' '.join(question['keywords']))\n",
    "    question['documents_api'] = documents\n",
    "\n",
    "    print(f\"Documents found for question `{question['id']}`: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e64fd7",
   "metadata": {},
   "source": [
    "### Step 3: Rank documents with \"Traditional IR\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acb6805e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked documents for question `55031181e9bde69634000014`:\n",
      "Document ID: 15617541, Score: 1.0713616533282146\n",
      "Document ID: 15829955, Score: 0.9393249488260605\n",
      "Document ID: 12239580, Score: 0.8723052363678908\n",
      "\n",
      "\n",
      "Skipping question `55046d5ff8aee20f27000007` due to no documents found.\n",
      "\n",
      "Ranked documents for question `54e25eaaae9738404b000017`:\n",
      "Document ID: 15094122, Score: 1.0153747819406589\n",
      "Document ID: 11076767, Score: 1.0045996513693458\n",
      "Document ID: 38284126, Score: 0.9014224564351652\n",
      "Document ID: 21784067, Score: 0.6323846734404047\n",
      "\n",
      "\n",
      "Ranked documents for question `535d292a9a4572de6f000003`:\n",
      "Document ID: 35940442, Score: 7.196373859909771\n",
      "Document ID: 33835135, Score: 4.008976980135349\n",
      "Document ID: 33767452, Score: 3.8572114432991196\n",
      "Document ID: 35923905, Score: 3.732640956178657\n",
      "Document ID: 37543950, Score: 3.697055238237451\n",
      "Document ID: 33201478, Score: 3.545103756873269\n",
      "Document ID: 33300079, Score: 3.0357011242198104\n",
      "Document ID: 38706580, Score: 3.0297871162329604\n",
      "Document ID: 36789427, Score: 2.9152448552605614\n",
      "Document ID: 33799493, Score: 2.771852751860813\n",
      "\n",
      "\n",
      "Ranked documents for question `55262a9787ecba3764000009`:\n",
      "Document ID: 39500402, Score: 6.295508020275088\n",
      "Document ID: 37832903, Score: 5.858597057768362\n",
      "Document ID: 37298085, Score: 5.603492435408204\n",
      "Document ID: 36982891, Score: 5.346629360073992\n",
      "Document ID: 38788984, Score: 5.267493520879981\n",
      "Document ID: 39640194, Score: 4.998559846060382\n",
      "Document ID: 39766208, Score: 4.971770520477231\n",
      "Document ID: 37094446, Score: 4.952920908582282\n",
      "Document ID: 38097649, Score: 4.690737261336546\n",
      "Document ID: 38283827, Score: 4.6470608128972515\n",
      "\n",
      "\n",
      "Skipping question `51406e6223fec90375000009` due to no documents found.\n",
      "\n",
      "Ranked documents for question `553fa78b1d53b76422000007`:\n",
      "Document ID: 36591520, Score: 6.416841713548074\n",
      "Document ID: 33261630, Score: 6.030195549607112\n",
      "Document ID: 32336272, Score: 5.9782510597323295\n",
      "Document ID: 30264202, Score: 5.961002266348866\n",
      "Document ID: 33910598, Score: 5.853380665544138\n",
      "Document ID: 25808651, Score: 5.451519431459019\n",
      "Document ID: 36969852, Score: 5.205792209132218\n",
      "Document ID: 32111227, Score: 5.156104334851949\n",
      "Document ID: 27492604, Score: 5.118770577816262\n",
      "Document ID: 27402147, Score: 4.706776556056165\n",
      "\n",
      "\n",
      "Ranked documents for question `5149199dd24251bc05000040`:\n",
      "Document ID: 29655452, Score: 10.893100983147379\n",
      "Document ID: 38308492, Score: 10.06070870995914\n",
      "Document ID: 33371107, Score: 9.497933231505037\n",
      "Document ID: 32918950, Score: 9.286892945857252\n",
      "Document ID: 38741505, Score: 9.225374774070655\n",
      "Document ID: 38882969, Score: 9.00562859903633\n",
      "Document ID: 29321572, Score: 8.911436374871732\n",
      "Document ID: 37082493, Score: 8.473501357036735\n",
      "Document ID: 38759248, Score: 8.439704660252383\n",
      "Document ID: 35796650, Score: 8.242272333540408\n",
      "\n",
      "\n",
      "Ranked documents for question `52bf1db603868f1b06000011`:\n",
      "Document ID: 21170699, Score: 1.3559705922728171\n",
      "Document ID: 21208140, Score: 1.1249174430069635\n",
      "Document ID: 39294041, Score: 1.1054921369023323\n",
      "Document ID: 24126422, Score: 1.0787981376626097\n",
      "\n",
      "\n",
      "Skipping question `5709e4b2cf1c32585100001c` due to no documents found.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "for question in bioasq_13b_questions:\n",
    "\n",
    "    # ---------------- Process the documents ----------------\n",
    "    # For each question, concatenate the title and abstract of each of its document\n",
    "    full_doc = [doc[\"title\"] + \" \" + doc[\"documentAbstract\"] for doc in question['documents_api']]\n",
    "\n",
    "    # Tokenize the full documents (title + abstract) of the question\n",
    "    tokenized_docs = [word_tokenize(doc.lower()) for doc in full_doc]\n",
    "    \n",
    "    # Tokenize the question (question body)\n",
    "    tokenized_question = word_tokenize(question['body'].lower())\n",
    "\n",
    "    # ---------------- Score the documents ----------------\n",
    "    # Create bm25 instance\n",
    "    # Check if there are any documents to process, if not, skip the question\n",
    "    if not tokenized_docs:\n",
    "        print(f\"Skipping question `{question['id']}` due to no documents found.\\n\")\n",
    "        continue\n",
    "\n",
    "    # Crea la instancia de BM25\n",
    "    bm25 = BM25Okapi(tokenized_docs)\n",
    "\n",
    "    # Get the scores for the query\n",
    "    scores = bm25.get_scores(tokenized_question)\n",
    "\n",
    "    # Sort documents by score\n",
    "    ranked_docs = sorted(zip(question['documents_api'], scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Keep the top 10 documents\n",
    "    top_docs = [doc for doc, score in ranked_docs[:10]]\n",
    "\n",
    "    print(f\"Ranked documents for question `{question['id']}`:\")\n",
    "    \n",
    "    # Print the top 10 documents id with their scores\n",
    "    for doc, score in ranked_docs[:10]:\n",
    "        print(f\"Document ID: {doc['pmid']}, Score: {score}\")\n",
    "    print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
