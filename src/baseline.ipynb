{
 "cells": [
  {
   "cell_type": "code",
   "id": "9a1fbb59",
   "metadata": {},
   "source": [
    "# Importing necessary libraries\n",
    "import requests\n",
    "import json\n",
    "import string\n",
    "\n",
    "# Download nltk stopwords and punkt tokenizer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import word_tokenize"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "929bceaf",
   "metadata": {},
   "source": [
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1af1cf5e",
   "metadata": {},
   "source": [
    "## Loading training data"
   ]
  },
  {
   "cell_type": "code",
   "id": "5d1db5d0",
   "metadata": {},
   "source": [
    "from utils import load_bioasq_questions\n",
    "bioasq_13b_questions = load_bioasq_questions('../data/BioASQ-training13b/training13b.json', num_questions=10)\n",
    "\n",
    "# Check the number of questions\n",
    "print(f\"Number of BioASQ 13b questions: {len(bioasq_13b_questions)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fd7cdd0f",
   "metadata": {},
   "source": [
    "## PubMed's API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea062f0f",
   "metadata": {},
   "source": [
    "## Traditional IR model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaaa825",
   "metadata": {},
   "source": [
    "### Step 1: Extract keywords from questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea21062",
   "metadata": {},
   "source": [
    "#### Remove stop words and punctuation"
   ]
  },
  {
   "cell_type": "code",
   "id": "4c9529fc",
   "metadata": {},
   "source": [
    "from utils import extract_keywords\n",
    "\n",
    "# For each question, extract keywords and save them in a attribute keywords\n",
    "for question in bioasq_13b_questions:\n",
    "    question['keywords'] = extract_keywords(question['body'])\n",
    "\n",
    "print(\"Original question body:\")\n",
    "print(bioasq_13b_questions[0]['body'])\n",
    "print(\"\\nExtracted keywords:\")\n",
    "print(bioasq_13b_questions[0]['keywords'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "343bd797",
   "metadata": {},
   "source": [
    "### Step 2: Consume PubMed's API to get relevant documents"
   ]
  },
  {
   "cell_type": "code",
   "id": "5c57ebe7",
   "metadata": {},
   "source": [
    "# Get the most relevant documents for each question according to the PubMed API\n",
    "# and save them in a new attribute documents_api\n",
    "from utils import get_most_relevant_documents\n",
    "\n",
    "for question in bioasq_13b_questions:\n",
    "    documents = get_most_relevant_documents(' '.join(question['keywords']))\n",
    "    question['documents_api'] = documents\n",
    "\n",
    "    print(f\"Documents found for question `{question['id']}`: {len(documents)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "74e64fd7",
   "metadata": {},
   "source": [
    "### Step 3: Rank documents with \"Traditional IR\" model"
   ]
  },
  {
   "cell_type": "code",
   "id": "acb6805e",
   "metadata": {},
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "for question in bioasq_13b_questions:\n",
    "\n",
    "    # ---------------- Process the documents ----------------\n",
    "    # For each question, concatenate the title and abstract of each of its document\n",
    "    full_doc = [doc[\"title\"] + \" \" + doc[\"documentAbstract\"] for doc in question['documents_api']]\n",
    "\n",
    "    # Tokenize the full documents (title + abstract) of the question\n",
    "    tokenized_docs = [word_tokenize(doc.lower()) for doc in full_doc]\n",
    "    \n",
    "    # Tokenize the question (question body)\n",
    "    tokenized_question = word_tokenize(question['body'].lower())\n",
    "\n",
    "    # ---------------- Score the documents ----------------\n",
    "    # Create bm25 instance\n",
    "    bm25 = BM25Okapi(tokenized_docs)\n",
    "\n",
    "    # Get the scores for the query\n",
    "    scores = bm25.get_scores(tokenized_question)\n",
    "\n",
    "    # Sort documents by score\n",
    "    ranked_docs = sorted(zip(question['documents_api'], scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Keep the top 10 documents\n",
    "    top_docs = [doc for doc, score in ranked_docs[:10]]\n",
    "\n",
    "    print(f\"Ranked documents for question `{question['id']}`:\")\n",
    "    \n",
    "    # Print the top 10 documents id with their scores\n",
    "    for doc, score in ranked_docs[:10]:\n",
    "        print(f\"Document ID: {doc['pmid']}, Score: {score}\")\n",
    "    print(\"\\n\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e238e0d3339fbb06",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
