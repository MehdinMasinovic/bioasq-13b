{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Import of packages and pre-trained BERT model",
   "id": "828a180633c026ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Importing necessary libraries\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "import requests\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "# BioBERT is a good choice as it's trained on biomedical literature\n",
    "MODEL_NAME = \"dmis-lab/biobert-base-cased-v1.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " #### Loading and Processing the BioASQ Dataset (Similar to Baseline)",
   "id": "321882a56975cbd3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from utils import load_bioasq_questions\n",
    "bioasq_13b_questions = load_bioasq_questions('../data/BioASQ-training13b/training13b.json', num_questions=10)\n",
    "\n",
    "# Check the number of questions\n",
    "print(f\"Number of BioASQ 13b questions: {len(bioasq_13b_questions)}\")"
   ],
   "id": "4b137d09e18bc579",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_embeddings(texts, model, tokenizer, max_length=512):\n",
    "    \"\"\"\n",
    "    Generate embeddings for a list of texts using the provided model and tokenizer.\n",
    "    \n",
    "    Args:\n",
    "        texts (list): List of text strings to embed\n",
    "        model: Transformer model\n",
    "        tokenizer: Tokenizer for the model\n",
    "        max_length (int): Maximum sequence length\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Array of embeddings\n",
    "    \"\"\"\n",
    "    # Tokenize texts\n",
    "    encoded_input = tokenizer(\n",
    "        texts, \n",
    "        padding=True, \n",
    "        truncation=True, \n",
    "        max_length=max_length, \n",
    "        return_tensors='pt'\n",
    "    ).to(device)\n",
    "    \n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    \n",
    "    # Mean pooling - take average of all token embeddings\n",
    "    attention_mask = encoded_input['attention_mask']\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(model_output.last_hidden_state.size()).float()\n",
    "    sum_embeddings = torch.sum(model_output.last_hidden_state * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    embeddings = sum_embeddings / sum_mask\n",
    "    \n",
    "    # Convert from PyTorch tensor to numpy array\n",
    "    return embeddings.cpu().numpy() "
   ],
   "id": "8b96c6918f3789ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### PubMed API Integration",
   "id": "1411a03a675f9f86"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Neural Document Retrieval",
   "id": "401d498cf461f25a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from utils import get_most_relevant_documents\n",
    "from utils import extract_keywords\n",
    "def retrieve_and_rank_documents_neural(question, model, tokenizer, max_docs=50):\n",
    "    \"\"\"\n",
    "    Retrieve documents using the PubMed API and rank them using neural embeddings.\n",
    "    \n",
    "    Args:\n",
    "        question (dict): Question dictionary with 'body' field\n",
    "        model: Transformer model for embeddings\n",
    "        tokenizer: Tokenizer for the model\n",
    "        max_docs (int): Maximum number of documents to retrieve initially\n",
    "        \n",
    "    Returns:\n",
    "        list: Top 10 ranked documents\n",
    "    \"\"\"\n",
    "    # Extract keywords for API search (same as baseline)\n",
    "    keywords = ' '.join(extract_keywords(question['body']))\n",
    "    \n",
    "    # Get documents from PubMed API\n",
    "    documents = get_most_relevant_documents(keywords, documents_per_page=max_docs)\n",
    "    \n",
    "    if not documents:\n",
    "        return []\n",
    "    \n",
    "    # Create text representations for documents (title + abstract)\n",
    "    doc_texts = [f\"{doc['title']} {doc['documentAbstract']}\" for doc in documents]\n",
    "    \n",
    "    # Generate embeddings for question and documents\n",
    "    question_embedding = get_embeddings([question['body']], model, tokenizer)[0]\n",
    "    document_embeddings = get_embeddings(doc_texts, model, tokenizer)\n",
    "    \n",
    "    # Calculate cosine similarity between question and each document\n",
    "    similarities = cosine_similarity([question_embedding], document_embeddings)[0]\n",
    "    \n",
    "    # Combine documents with their similarity scores and sort\n",
    "    ranked_docs = sorted(zip(documents, similarities), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return top 10 documents\n",
    "    return [doc for doc, _ in ranked_docs[:10]]"
   ],
   "id": "b1d1775fdb81ac32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Neural Snippet Extraction",
   "id": "9f4bc8ae18e1adaf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_and_rank_snippets_neural(question, documents, model, tokenizer, max_snippets=10):\n",
    "    \"\"\"\n",
    "    Extract snippets from documents and rank them using neural embeddings.\n",
    "    \n",
    "    Args:\n",
    "        question (dict): Question dictionary with 'body' field\n",
    "        documents (list): List of document dictionaries\n",
    "        model: Transformer model for embeddings\n",
    "        tokenizer: Tokenizer for the model\n",
    "        max_snippets (int): Maximum number of snippets to return\n",
    "        \n",
    "    Returns:\n",
    "        list: Top ranked snippets with metadata\n",
    "    \"\"\"\n",
    "    # Generate question embedding\n",
    "    question_embedding = get_embeddings([question['body']], model, tokenizer)[0]\n",
    "    \n",
    "    all_snippets = []\n",
    "    \n",
    "    # Process each document\n",
    "    for doc in documents:\n",
    "        # Combine title and abstract\n",
    "        full_text = f\"{doc['title']} {doc['documentAbstract']}\"\n",
    "        \n",
    "        # Split into sentences\n",
    "        sentences = sent_tokenize(full_text)\n",
    "        \n",
    "        # Track offsets for each sentence\n",
    "        current_offset = 0\n",
    "        sentence_offsets = []\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            start_offset = full_text.find(sentence, current_offset)\n",
    "            end_offset = start_offset + len(sentence) - 1\n",
    "            sentence_offsets.append((start_offset, end_offset))\n",
    "            current_offset = end_offset + 1\n",
    "        \n",
    "        # Generate embeddings for all sentences\n",
    "        if sentences:\n",
    "            sentence_embeddings = get_embeddings(sentences, model, tokenizer)\n",
    "            \n",
    "            # Calculate similarity scores\n",
    "            similarities = cosine_similarity([question_embedding], sentence_embeddings)[0]\n",
    "            \n",
    "            # Create snippet objects with metadata\n",
    "            for i, (sentence, score) in enumerate(zip(sentences, similarities)):\n",
    "                start_offset, end_offset = sentence_offsets[i]\n",
    "                \n",
    "                # Determine if this is from title or abstract\n",
    "                if start_offset < len(doc['title']):\n",
    "                    section = \"title\"\n",
    "                else:\n",
    "                    section = \"abstract\"\n",
    "                    # Adjust offset for abstract\n",
    "                    if start_offset >= len(doc['title']):\n",
    "                        start_offset = start_offset - len(doc['title']) - 1\n",
    "                        end_offset = end_offset - len(doc['title']) - 1\n",
    "                \n",
    "                snippet = {\n",
    "                    'document': f\"http://www.ncbi.nlm.nih.gov/pubmed/{doc['pmid']}\",\n",
    "                    'text': sentence,\n",
    "                    'offsetInBeginSection': start_offset,\n",
    "                    'offsetInEndSection': end_offset,\n",
    "                    'beginSection': section,\n",
    "                    'endSection': section,\n",
    "                    'score': float(score)\n",
    "                }\n",
    "                all_snippets.append(snippet)\n",
    "    \n",
    "    # Sort all snippets by score and select top ones\n",
    "    ranked_snippets = sorted(all_snippets, key=lambda x: x['score'], reverse=True)\n",
    "    \n",
    "    return ranked_snippets[:max_snippets]"
   ],
   "id": "855e5e90e929db1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Main Processing Pipeline",
   "id": "46f8def39425c397"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Process all questions\n",
    "results = []\n",
    "\n",
    "for question in bioasq_13b_questions:\n",
    "    print(f\"Processing question: {question['id']}\")\n",
    "    \n",
    "    # 1. Retrieve and rank documents using neural approach\n",
    "    ranked_docs = retrieve_and_rank_documents_neural(\n",
    "        question, \n",
    "        model, \n",
    "        tokenizer, \n",
    "        max_docs=3\n",
    "    )\n",
    "    \n",
    "    # 2. Extract and rank snippets using neural approach\n",
    "    ranked_snippets = extract_and_rank_snippets_neural(\n",
    "        question,\n",
    "        ranked_docs,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        max_snippets=3\n",
    "    )\n",
    "    \n",
    "    # 3. Format result for this question\n",
    "    question_result = {\n",
    "        'id': question['id'],\n",
    "        'documents': [f\"http://www.ncbi.nlm.nih.gov/pubmed/{doc['pmid']}\" for doc in ranked_docs],\n",
    "        'snippets': ranked_snippets\n",
    "    }\n",
    "    \n",
    "    results.append(question_result)\n",
    "    \n",
    "    print(f\"Found {len(ranked_docs)} documents and {len(ranked_snippets)} snippets\")\n",
    "\n",
    "# Save results to file\n",
    "with open('neural_results.json', 'w') as f:\n",
    "    json.dump({'questions': results}, f, indent=2)"
   ],
   "id": "fc4e1c93c2ef8663",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
